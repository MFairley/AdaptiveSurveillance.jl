library(data.table)
library(survival)
library(survminer)
library(ggplot2)
library(scales)
library(stringr)
library(latex2exp)
results_path <- here("results", "tmp", "mfairley")
header <- c("p1", "p2", "p3", "p4", "p5","a0", "a1", "a2", "a3", "a4", "a5") # assuming 5 locations
# Scenario: g, p1, p2
read_scenario_alg <- function(alg, g, p1, p2) {
atd_alg.dt <- fread(paste(results_path, paste0("atd_", alg, "_", g, "_", p1, "_", p2, ".csv"), sep="/"), col.names = header)
atd_alg.dt[, t := 1:.N]
atd_alg.dt[, alg := alg]
atd_alg.dt[, g := factor(g)]
atd_alg.dt[, p1p2 := factor(paste0(p1, "_", p2))]
return(atd_alg.dt)
}
read_scenario <- function(g, p1, p2) {
atd_constant.dt <- read_scenario_alg("constant", g, p1, p2)
atd_random.dt <- read_scenario_alg("random", g, p1, p2)
atd_thompson.dt <- read_scenario_alg("thompson", g, p1, p2)
atd_evsi.dt <- read_scenario_alg("evsi", g, p1, p2)
atd.dt <- rbindlist(list(constant=atd_constant.dt,random=atd_random.dt,thompson=atd_thompson.dt,evsi=atd_evsi.dt), use.names = T, idcol = "alg")
return(atd.dt)
}
individual_format <- function (atd.dt) { # assuming outbreak in location 1 to do: make this generalize to L locations
d1 <- data.table(t = rep(atd.dt$t, atd.dt$a1), status = 1)[!is.na(t)] # <- outbreak location
d2 <- data.table(t = rep(atd.dt$t, atd.dt$a0), status = 0)[!is.na(t)] # to do: make this not throw a warning
d3 <- data.table(t = rep(atd.dt$t, atd.dt$a2), status = 0)[!is.na(t)]
d4 <- data.table(t = rep(atd.dt$t, atd.dt$a3), status = 0)[!is.na(t)]
d5 <- data.table(t = rep(atd.dt$t, atd.dt$a4), status = 0)[!is.na(t)]
d6 <- data.table(t = rep(atd.dt$t, atd.dt$a5), status = 0)[!is.na(t)]
ind.dt <- rbindlist(list(d1, d2, d3, d4, d5, d6))
return(ind.dt)
}
read_scenario_individual <- function(g, p1, p2) {
atd_constant.dt <- individual_format(read_scenario_alg("constant", g, p1, p2))
atd_random.dt <-individual_format(read_scenario_alg("random", g, p1, p2))
atd_thompson.dt <- individual_format(read_scenario_alg("thompson", g, p1, p2))
atd_evsi.dt <- individual_format(read_scenario_alg("evsi", g, p1, p2))
atd.dt <- rbindlist(list(constant=atd_constant.dt,random=atd_random.dt,thompson=atd_thompson.dt,evsi=atd_evsi.dt), use.names = T, idcol = "alg")
atd.dt[, alg := factor(alg, levels = c("constant", "evsi", "thompson", "random"), labels = c("Clairvoyance", "Profile Likelihood", "Thompson Sampling", "Uniform Random"))]
atd.dt[, g := factor(g,)]
atd.dt[, p1p2 := paste0(p1, "_", p2)]
return(atd.dt)
}
### RESULTS
# Read in all scenarios and combine
atd_ind_1_1_1.dt <- read_scenario_individual(1, 0.01, 0.01)
atd_ind_1_1_2.dt <- read_scenario_individual(1, 0.01, 0.02)
atd_ind_1_2_1.dt <- read_scenario_individual(1, 0.02, 0.01)
atd_ind_50_1_1.dt <- read_scenario_individual(50, 0.01, 0.01)
atd_ind_50_1_2.dt <- read_scenario_individual(50, 0.01, 0.02)
atd_ind_50_2_1.dt <- read_scenario_individual(50, 0.02, 0.01)
atd_ind.dt <- rbindlist(list(atd_ind_1_1_1.dt, atd_ind_1_1_2.dt,
atd_ind_1_2_1.dt, atd_ind_50_1_1.dt,
atd_ind_50_1_2.dt, atd_ind_50_2_1.dt))
atd_ind.dt[g == 50, .(fa=sum((status == 1) && (t < as.numeric(g))) + sum(status == 0), n=.N), by = .(p1p2, alg, g)]
source('~/Projects/AdaptiveSurveillance/results/performance_analysis.R')
atd_ind.dt[g == 50, .(fa=sum((status == 1) && (t < as.numeric(g))) + sum(status == 0), n=.N), by = .(p1p2, alg, g)]
atd_ind.dt[, .(fa=sum((status == 1) && (t < as.numeric(g))) + sum(status == 0), n=.N), by = .(p1p2, alg, g)]
# False Alarm Probability for all locations
fap.dt <- atd_ind.dt[, .(fa=sum((status == 1) && (t < as.numeric(g))) + sum(status == 0), n=.N), by = .(p1p2, alg, g)]
fap.dt
fap.dt[, fap := g / n]
fap.dt[, fap := fa / n]
fap.dt[, hw := sqrt(p * (1-p) / n)]
fap.dt[, p := fa / n]
fap.dt[, hw := sqrt(p * (1-p) / n)]
fap.dt
fap.dt[, lower : p - hw]
fap.dt[, upper : p + hw]
fap.dt[, lower := p - hw]
fap.dt[, upper := p + hw]
fap.dt
fap.dt[, fprob_fmt := paste0(comma(p, accuracy = acc), " [", comma(lower, accuracy = acc), ", ", comma(upper, accuracy = acc), "]")]
acc=0.01
fap.dt[, fprob_fmt := paste0(comma(p, accuracy = acc), " [", comma(lower, accuracy = acc), ", ", comma(upper, accuracy = acc), "]")]
fap.dt
# Publication Table of Results
tor.dt <- med.dt
tor.dt[, c("alg", "g", "p1p2") := tstrsplit(scenario, ",", fixed=T)]
tor.dt[, c("alg", "g", "p1p2") := list(str_trim(gsub(".*=","",alg)), str_trim(gsub(".*=","",g)), str_trim(gsub(".*=","",p1p2)))]
tor.dt <- merge(tor.dt, fap.dt[, p1p2, alg, g, fprob_fmt], by = c("p1p2, alg, g"))
tor.dt <- merge(tor.dt, fap.dt[, p1p2, alg, g, fprob_fmt], by = c("p1p2", "alg", "g"))
tor.dt <- merge(tor.dt, fap.dt[, .(p1p2, alg, g, fprob_fmt)], by = c("p1p2", "alg", "g"))
tor.dt
# <-
tor.dt <-  dcast(tor.dt, p1p2 + alg ~ g, value.var = c("fprob_fmt", "med_fmt"))
tor.dt
# False Alarm Probability for all locations
fap.dt <- atd_ind.dt[, .(fa=sum((status == 1) && (t < as.numeric(g))) + sum(status == 0), n=.N), by = .(p1p2, alg, g)]
fap.dt
# False Alarm Probability for all locations
fap.dt <- atd_ind.dt[, .(fa=sum((status == 1) & (t < as.numeric(g))) + sum(status == 0), n=.N), by = .(p1p2, alg, g)]
fap.dt
atd_ind.dt[, status == 1 & t < as.numeric(g)]
atd_ind.dt[status == 1 & t < as.numeric(g)]
atd_ind.dt[status == 1 & t < as.numeric(as.character(g))]
# False Alarm Probability for all locations
fap.dt <- atd_ind.dt[, .(fa=sum((status == 1) & (t < as.numeric(as.character(g)))) + sum(status == 0), n=.N), by = .(p1p2, alg, g)]
fap.dt
source('~/Projects/AdaptiveSurveillance/results/performance_analysis.R')
tor.dt
output_path <-  here("results", "tmp")
source('~/Projects/AdaptiveSurveillance/results/performance_analysis.R')
ggplot(sfit.dt, aes(x = time, y = alarm, ymin=alarm_lower, ymax=alarm_upper, fill=alg, color=alg)) +
facet_grid(rows = vars(p1p2), cols = vars(g)) + xlim(0, 150) +
geom_step() + # to do: add CI
xlab("Time (weeks)") + ylab("Cumulative Probability of Alarm in Location 1") +
scale_color_discrete(name = "Algorithm") +
theme(legend.position = "bottom")
ggsave(paste(output_path, "survival_curves.pdf", sep="/"), width=8, height=8)
?geom_step
fap.dt
fap.dt
med.dt
# Median Delay
median_cond_delay <- function(g_sel, acc=1.0) {
sfit_delay <-  survfit(Surv(t, status) ~ alg + g + p1p2, data = atd_ind.dt[g == g_sel], start.time = g_sel - 1)
quantile_delay <- quantile(sfit_delay, 0.5) # median
res_delay.dt <- data.table(data.frame(quantile_delay), keep.rownames = T)
setnames(res_delay.dt, names(res_delay.dt), c("scenario", "q50", "low", "up"))
res_delay.dt[, q50_s := q50 - g_sel]
res_delay.dt[, low_s := low - g_sel]
res_delay.dt[, up_s := up - g_sel]
res_delay.dt[, med_fmt := paste0(comma(q50_s, accuracy = acc), " [", comma(low_s, accuracy = acc), ", ", comma(up_s, accuracy = acc), "]")]
return(res_delay.dt[, .(scenario, med_fmt, q50s)])
}
med1.dt <- median_cond_delay(1)
med50.dt <- median_cond_delay(50)
# Median Delay
median_cond_delay <- function(g_sel, acc=1.0) {
sfit_delay <-  survfit(Surv(t, status) ~ alg + g + p1p2, data = atd_ind.dt[g == g_sel], start.time = g_sel - 1)
quantile_delay <- quantile(sfit_delay, 0.5) # median
res_delay.dt <- data.table(data.frame(quantile_delay), keep.rownames = T)
setnames(res_delay.dt, names(res_delay.dt), c("scenario", "q50", "low", "up"))
res_delay.dt[, q50_s := q50 - g_sel]
res_delay.dt[, low_s := low - g_sel]
res_delay.dt[, up_s := up - g_sel]
res_delay.dt[, med_fmt := paste0(comma(q50_s, accuracy = acc), " [", comma(low_s, accuracy = acc), ", ", comma(up_s, accuracy = acc), "]")]
return(res_delay.dt[, .(scenario, med_fmt, q50_s)])
}
med1.dt <- median_cond_delay(1)
med50.dt <- median_cond_delay(50)
med.dt <- rbindlist(list(med1.dt, med50.dt))
med.dt
# Publication Table of Results
tor.dt <- med.dt
tor.dt[, c("alg", "g", "p1p2") := tstrsplit(scenario, ",", fixed=T)]
tor.dt[, c("alg", "g", "p1p2") := list(str_trim(gsub(".*=","",alg)), str_trim(gsub(".*=","",g)), str_trim(gsub(".*=","",p1p2)))]
tor.dt <- merge(tor.dt, fap.dt[, .(p1p2, alg, g, p, fprob_fmt)], by = c("p1p2", "alg", "g"))
tor.dt
tor_raw.dt <- tor.dt[, .(p1p2, alg, g, p, q50_s)]
tor_raw.dt
# 2D plot
ggplot(tor_raw.dt, aes(x = p, y = q50_s, color=alg)) +
facet_grid(rows(p1p2), cols(s))
# 2D plot
ggplot(tor_raw.dt, aes(x = p, y = q50_s, color=alg)) +
facet_grid(vars(p1p2), vars(g))
# 2D plot
ggplot(tor_raw.dt, aes(x = p, y = q50_s, color=alg)) +
facet_grid(vars(p1p2), vars(g)) + geom_point()
# 2D plot
ggplot(tor_raw.dt, aes(x = p, y = q50_s, color=alg)) +
facet_grid(vars(p1p2), vars(g)) + geom_point() +
guide(legend.position = "bottom")
# 2D plot
ggplot(tor_raw.dt, aes(x = p, y = q50_s, color=alg)) +
facet_grid(vars(p1p2), vars(g)) + geom_point() +
theme(legend.position = "bottom")
# 2D plot
ggplot(tor_raw.dt, aes(x = p, y = q50_s, color=alg)) +
facet_grid(vars(p1p2), vars(g)) + geom_point() +
theme(legend.position = "bottom")
ggsave(paste(output_path, "trade_off", sep="/"), width=8, height=8)
ggsave(paste(output_path, "trade_off.pdf", sep="/"), width=8, height=8)
?rep
L <- 5
header <- c(sprintf("p%d",seq(1:L)), sprintf("a%d",seq(0:L)))
seq(0:L)
?seq
header <- c(sprintf("p%d",seq(1:L)), sprintf("a%d",seq(from = 0, to = L)))
# Scenario / Experiment: alg, g, p1, p2
read_scenario_alg <- function(alg, g, p1, p2) {
atd_alg.dt <- fread(paste(results_path, paste0("atd_", alg, "_", g, "_", p1, "_", p2, ".csv"), sep="/"), col.names = header)
atd_alg.dt[, t := 1:.N]
atd_alg.dt[, alg := alg]
atd_alg.dt[, g := factor(g)]
atd_alg.dt[, p1p2 := factor(paste0(p1, "_", p2))]
return(atd_alg.dt)
}
read_scenario <- function(g, p1, p2, algs = c("constant", "random", "thompson", "evsi")) {
atd.dt <- data.table()
for (a in algs) {
tmp.dt <- read_scenario_alg(a, g, p1, p2)
atd.dt <- rbindlist(list(atd.dt, tmp.dt), use.names = T)
}
return(atd.dt)
}
read_scenario(1, 0.1, 0.1)
library(here)
library(data.table)
library(survival)
library(survminer)
library(ggplot2)
library(scales)
library(stringr)
library(latex2exp)
results_path <- here("results", "tmp", "mfairley")
output_path <-  here("results", "tmp")
read_scenario(1, 0.1, 0.1)
read_scenario(1, 0.01, 0.01)
# Scenario / Experiment: g, p1, p2, alg
read_scenario_alg <- function(g, p1, p2, alg) {
atd_alg.dt <- fread(paste(results_path, paste0("atd_", alg, "_", g, "_", p1, "_", p2, ".csv"), sep="/"), col.names = header)
atd_alg.dt[, t := 1:.N]
atd_alg.dt[, g := factor(g)]
atd_alg.dt[, p1p2 := factor(paste0(p1, "_", p2))]
atd_alg.dt[, alg := factor(alg)]
return(atd_alg.dt)
}
read_scenario <- function(g, p1, p2, algs = c("constant", "random", "thompson", "evsi"),
alg_labels = labels = c("Clairvoyance", "Profile Likelihood", "Thompson Sampling", "Uniform Random")) {
atd.dt <- data.table()
for (a in algs) {
tmp.dt <- read_scenario_alg(g, p1, p2, a)
atd.dt <- rbindlist(list(atd.dt, tmp.dt), use.names = T)
}
atd.dt[, alg := factor(alg, levels = algs, labels = alg_labels)]
return(atd.dt)
}
read_scenario <- function(g, p1, p2, algs = c("constant", "random", "thompson", "evsi"),
alg_labels = c("Clairvoyance", "Profile Likelihood", "Thompson Sampling", "Uniform Random")) {
atd.dt <- data.table()
for (a in algs) {
tmp.dt <- read_scenario_alg(g, p1, p2, a)
atd.dt <- rbindlist(list(atd.dt, tmp.dt), use.names = T)
}
atd.dt[, alg := factor(alg, levels = algs, labels = alg_labels)]
return(atd.dt)
}
read_scenario(1, 0.01, 0.01)
read_scenario(1, 0.01, 0.01)
a<-read_scenario(1, 0.01, 0.01)
a
a
?error
?stop
stop("problem")
read_scenario_alg_ind <- function (g, p1, p2, alg) {
atd.dt <- read_scenario_alg(g, p1, p2, alg)
a0s <- atd.dt[, sum(a0)]
if (a0s > 0) {
stop("a0 > 0")
}
# assuming outbreak in location 1
ind.dt <- data.table(t = rep(atd.dt$t, atd.dt$a1), status = 1)[!is.na(t)]
for (i in 2:L) {
if (atd.dt[, sum(a2)] > 0) {
tmp.dt <- data.table(t = rep(atd.dt$t, atd.dt[, paste0("a", i), with=F]), status = 0)[!is.na(t)]
ind.dt <- rbindlist(list(ind.dt, tmp.dt), use.names = T)
}
}
return(ind.dt)
}
read_scenario_ind <- function(g, p1, p2, algs = c("constant", "random", "thompson", "evsi"),
alg_labels = c("Clairvoyance", "Profile Likelihood", "Thompson Sampling", "Uniform Random")) {
atd.dt <- data.table()
for (a in algs) {
tmp.dt <- read_scenario_alg_ind(g, p1, p2, a)
atd.dt <- rbindlist(list(atd.dt, tmp.dt), use.names = T)
}
atd.dt[, alg := factor(alg, levels = algs, labels = alg_labels)]
return(atd.dt)
}
### RESULTS
# Read in all scenarios and combine
atd_ind_1_1_1.dt <- read_scenario_ind(1, 0.01, 0.01)
?with
library(here)
library(data.table)
library(survival)
library(survminer)
library(ggplot2)
library(scales)
library(stringr)
library(latex2exp)
results_path <- here("results", "tmp", "mfairley")
output_path <-  here("results", "tmp")
L <- 5
header <- c(sprintf("p%d",seq(1:L)), sprintf("a%d",seq(from = 0, to = L)))
# Scenario / Experiment: g, p1, p2, alg
read_scenario_alg <- function(g, p1, p2, alg) {
atd_alg.dt <- fread(paste(results_path, paste0("atd_", alg, "_", g, "_", p1, "_", p2, ".csv"), sep="/"), col.names = header)
atd_alg.dt[, t := 1:.N]
atd_alg.dt[, g := factor(g)]
atd_alg.dt[, p1p2 := factor(paste0(p1, "_", p2))]
atd_alg.dt[, alg := alg]
return(atd_alg.dt)
}
read_scenario <- function(g, p1, p2, algs = c("constant", "random", "thompson", "evsi"),
alg_labels = c("Clairvoyance", "Profile Likelihood", "Thompson Sampling", "Uniform Random")) {
atd.dt <- data.table()
for (a in algs) {
tmp.dt <- read_scenario_alg(g, p1, p2, a)
atd.dt <- rbindlist(list(atd.dt, tmp.dt), use.names = T)
}
atd.dt[, alg := factor(alg, levels = algs, labels = alg_labels)]
return(atd.dt)
}
read_scenario_alg_ind <- function (g, p1, p2, alg) {
atd.dt <- read_scenario_alg(g, p1, p2, alg)
a0s <- atd.dt[, sum(a0)]
if (a0s > 0) {
stop("a0 > 0")
}
# assuming outbreak in location 1
ind.dt <- data.table(t = rep(atd.dt$t, atd.dt$a1), status = 1)[!is.na(t)]
for (i in 2:L) {
if (atd.dt[, sum(a2)] > 0) {
tmp.dt <- data.table(t = rep(atd.dt$t, atd.dt[, paste0("a", i), with=F]), status = 0)[!is.na(t)]
ind.dt <- rbindlist(list(ind.dt, tmp.dt), use.names = T)
}
}
atd_alg.dt[, g := factor(g)]
atd_alg.dt[, p1p2 := factor(paste0(p1, "_", p2))]
atd_alg.dt[, alg := alg]
return(ind.dt)
}
read_scenario_ind <- function(g, p1, p2, algs = c("constant", "random", "thompson", "evsi"),
alg_labels = c("Clairvoyance", "Profile Likelihood", "Thompson Sampling", "Uniform Random")) {
atd.dt <- data.table()
for (a in algs) {
tmp.dt <- read_scenario_alg_ind(g, p1, p2, a)
atd.dt <- rbindlist(list(atd.dt, tmp.dt), use.names = T)
}
atd.dt[, alg := factor(alg, levels = algs, labels = alg_labels)]
return(atd.dt)
}
### RESULTS
# Read in all scenarios and combine
atd_ind_1_1_1.dt <- read_scenario_ind(1, 0.01, 0.01)
read_scenario_alg_ind <- function (g, p1, p2, alg) {
atd.dt <- read_scenario_alg(g, p1, p2, alg)
a0s <- atd.dt[, sum(a0)]
if (a0s > 0) {
stop("a0 > 0")
}
# assuming outbreak in location 1
ind.dt <- data.table(t = rep(atd.dt$t, atd.dt$a1), status = 1)[!is.na(t)]
for (i in 2:L) {
if (atd.dt[, sum(a2)] > 0) {
tmp.dt <- data.table(t = rep(atd.dt$t, atd.dt[, paste0("a", i), with=F]), status = 0)[!is.na(t)]
ind.dt <- rbindlist(list(ind.dt, tmp.dt), use.names = T)
}
}
ind.dt[, g := factor(g)]
ind.dt[, p1p2 := factor(paste0(p1, "_", p2))]
ind.dt[, alg := alg]
return(ind.dt)
}
read_scenario_ind <- function(g, p1, p2, algs = c("constant", "random", "thompson", "evsi"),
alg_labels = c("Clairvoyance", "Profile Likelihood", "Thompson Sampling", "Uniform Random")) {
atd.dt <- data.table()
for (a in algs) {
tmp.dt <- read_scenario_alg_ind(g, p1, p2, a)
atd.dt <- rbindlist(list(atd.dt, tmp.dt), use.names = T)
}
atd.dt[, alg := factor(alg, levels = algs, labels = alg_labels)]
return(atd.dt)
}
### RESULTS
# Read in all scenarios and combine
atd_ind_1_1_1.dt <- read_scenario_ind(1, 0.01, 0.01)
?dt
?data.table
?unlist
read_scenario_alg_ind <- function (g, p1, p2, alg) {
atd.dt <- read_scenario_alg(g, p1, p2, alg)
a0s <- atd.dt[, sum(a0)]
if (a0s > 0) {
stop("a0 > 0")
}
# assuming outbreak in location 1
ind.dt <- data.table(t = rep(atd.dt$t, atd.dt$a1), status = 1)[!is.na(t)]
for (i in 2:L) {
if (atd.dt[, sum(a2)] > 0) {
tmp.dt <- data.table(t = rep(atd.dt$t, unlist(atd.dt[, paste0("a", i), with=F])), status = 0)[!is.na(t)]
ind.dt <- rbindlist(list(ind.dt, tmp.dt), use.names = T)
}
}
ind.dt[, g := factor(g)]
ind.dt[, p1p2 := factor(paste0(p1, "_", p2))]
ind.dt[, alg := alg]
return(ind.dt)
}
### RESULTS
# Read in all scenarios and combine
atd_ind_1_1_1.dt <- read_scenario_ind(1, 0.01, 0.01)
atd_ind_1_1_1.dt
atd_ind_1_1_1.dt
read_scenario_individual <- function(g, p1, p2, algs = c("constant", "random", "thompson", "evsi"),
alg_labels = c("Clairvoyance", "Profile Likelihood", "Thompson Sampling", "Uniform Random")) {
atd.dt <- data.table()
for (a in algs) {
tmp.dt <- read_scenario_alg_ind(g, p1, p2, a)
atd.dt <- rbindlist(list(atd.dt, tmp.dt), use.names = T)
}
atd.dt[, alg := factor(alg, levels = algs, labels = alg_labels)]
return(atd.dt)
}
### RESULTS
# Read in all scenarios and combine
atd_ind_1_1_1.dt <- read_scenario_individual(1, 0.01, 0.01)
atd_ind_1_1_2.dt <- read_scenario_individual(1, 0.01, 0.02)
atd_ind_1_2_1.dt <- read_scenario_individual(1, 0.02, 0.01)
### RESULTS
# Read in all scenarios and combine
atd_ind_1_1_1.dt <- read_scenario_individual(1, 0.01, 0.01)
atd_ind_1_1_2.dt <- read_scenario_individual(1, 0.01, 0.02)
read_scenario_alg_ind <- function (g, p1, p2, alg) {
atd.dt <- read_scenario_alg(g, p1, p2, alg)
a0s <- atd.dt[, sum(a0)]
if (a0s > 0) {
stop("a0 > 0")
}
# assuming outbreak in location 1
ind.dt <- data.table(t = rep(atd.dt$t, atd.dt$a1), status = 1)[!is.na(t)]
for (i in 2:L) {
if (sum(atd.dt[, paste0("a", i), with=F]) > 0) {
tmp.dt <- data.table(t = rep(atd.dt$t, unlist(atd.dt[, paste0("a", i), with=F])), status = 0)[!is.na(t)]
ind.dt <- rbindlist(list(ind.dt, tmp.dt), use.names = T)
}
}
ind.dt[, g := factor(g)]
ind.dt[, p1p2 := factor(paste0(p1, "_", p2))]
ind.dt[, alg := alg]
return(ind.dt)
}
atd_ind_1_1_2.dt <- read_scenario_individual(1, 0.01, 0.02)
atd_ind_1_2_1.dt <- read_scenario_individual(1, 0.02, 0.01)
atd_ind_50_1_1.dt <- read_scenario_individual(50, 0.01, 0.01)
atd_ind_50_1_2.dt <- read_scenario_individual(50, 0.01, 0.02)
atd_ind_50_2_1.dt <- read_scenario_individual(50, 0.02, 0.01)
atd_ind.dt <- rbindlist(list(atd_ind_1_1_1.dt, atd_ind_1_1_2.dt,
atd_ind_1_2_1.dt, atd_ind_50_1_1.dt,
atd_ind_50_1_2.dt, atd_ind_50_2_1.dt))
# Fit survival curves
sfit <-  survfit(Surv(t, status) ~ alg + g + p1p2, data = atd_ind.dt)
# Publication plot
sfit.dt <- data.table(surv_summary(sfit))[, .(p1p2, alg, g, time, surv, upper, lower)]
# Publication plot
sfit.dt <- data.table(surv_summary(sfit, data = atd_ind.dt))[, .(p1p2, alg, g, time, surv, upper, lower)]
# add first points
sfit_add.dt <- data.table(p1p2 = unique(sfit.dt$p1p2), alg = unique(sfit.dt$alg), g = unique(sfit.dt$g), time = 0, surv = 1.0, upper = 1.0, lower = 1.0)
sfit.dt <- rbindlist(list(sfit.dt, sfit_add.dt))[order(p1p2, alg, g, time)]
sfit.dt[, c("alarm", "alarm_lower", "alarm_upper") := list(1 - surv, 1 - upper, 1 - lower)]
sfit.dt
ggplot(sfit.dt, aes(x = time, y = alarm, ymin=alarm_lower, ymax=alarm_upper, fill=alg, color=alg)) +
facet_grid(rows = vars(p1p2), cols = vars(g)) + xlim(0, 150) +
geom_step() + # to do: add CI
xlab("Time (weeks)") + ylab("Cumulative Probability of Alarm in Location 1") +
scale_color_discrete(name = "Algorithm") +
theme(legend.position = "bottom")
View(sfit.dt)
ggsave(paste(output_path, "survival_curves.pdf", sep="/"), width=8, height=8)
# False Alarm Probability for location 1 only
false_alarm_prob <- function(g_sel, acc=0.01) {
sfit_false <- survfit(Surv(t, status) ~ alg + g + p1p2, data = atd_ind.dt[g == g_sel])
res_false <- summary(sfit_false, times = g_sel)
res_false.dt <- data.table(scenario = rownames(res_false$table), fprob = 1 - res_false$surv, fprob_low = 1 - res_false$upper, fprob_high = 1 - res_false$lower)
res_false.dt[, fprob_fmt := paste0(comma(fprob, accuracy = acc), " [", comma(fprob_low, accuracy = acc), ", ", comma(fprob_high, accuracy = acc), "]")]
return(res_false.dt[, .(scenario, fprob_fmt)])
}
# False Alarm Probability for all locations
fap.dt <- atd_ind.dt[, .(fa=sum((status == 1) & (t < as.numeric(as.character(g)))) + sum(status == 0), n=.N), by = .(p1p2, alg, g)]
comma(0.03567)
# False Alarm Probability for all locations
fap.dt <- atd_ind.dt[, .(fa=sum((status == 1) & (t < as.numeric(as.character(g)))) + sum(status == 0), n=.N), by = .(p1p2, alg, g)]
fap.dt[, p := fa / n]
fap.dt[, hw := sqrt(p * (1-p) / n)]
fap.dt[, lower := p - hw]
fap.dt[, upper := p + hw]
acc=0.01
fap.dt[, fprob_fmt := paste0(comma(p, accuracy = acc), " [", comma(lower, accuracy = acc), ", ", comma(upper, accuracy = acc), "]")]
fap.dt
# Median Delay
median_cond_delay <- function(g_sel, acc=1.0) {
sfit_delay <-  survfit(Surv(t, status) ~ alg + g + p1p2, data = atd_ind.dt[g == g_sel], start.time = g_sel - 1)
quantile_delay <- quantile(sfit_delay, 0.5) # median
res_delay.dt <- data.table(data.frame(quantile_delay), keep.rownames = T)
setnames(res_delay.dt, names(res_delay.dt), c("scenario", "q50", "low", "up"))
res_delay.dt[, q50_s := q50 - g_sel]
res_delay.dt[, low_s := low - g_sel]
res_delay.dt[, up_s := up - g_sel]
res_delay.dt[, med_fmt := paste0(comma(q50_s, accuracy = acc), " [", comma(low_s, accuracy = acc), ", ", comma(up_s, accuracy = acc), "]")]
return(res_delay.dt[, .(scenario, med_fmt, q50_s)])
}
med1.dt <- median_cond_delay(1)
med50.dt <- median_cond_delay(50)
med.dt <- rbindlist(list(med1.dt, med50.dt))
med.dt <- rbindlist(list(med1.dt, med50.dt))
med.dt[, c("alg", "g", "p1p2") := tstrsplit(scenario, ",", fixed=T)]
med.dt[, c("alg", "g", "p1p2") := list(str_trim(gsub(".*=","",alg)), str_trim(gsub(".*=","",g)), str_trim(gsub(".*=","",p1p2)))]
# Publication Table of Results
tor.dt <- merge(med.dt, fap.dt[, .(p1p2, alg, g, p, fprob_fmt)], by = c("p1p2", "alg", "g"))
tor.dt <- tor.dt[, .(p1p2, alg, g, fprob_fmt, med_fmt)]
tor.dt <-  dcast(tor.dt, p1p2 + alg ~ g, value.var = c("fprob_fmt", "med_fmt"))
tor.dt
